{
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.12",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "gpu",
      "dataSources": [
        {
          "sourceId": 97570,
          "databundleVersionId": 11600808,
          "sourceType": "competition"
        }
      ],
      "dockerImageVersionId": 30919,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": true
    },
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "8d4009274f9f489a83bbe9ee023fc29a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_633b94e846b64773a62bc1c79f602224",
              "IPY_MODEL_2c9801bc180f4ef5afa41d668370d6f4",
              "IPY_MODEL_2543180a25214e6a881093bd82e6b6e4"
            ],
            "layout": "IPY_MODEL_0709f861b26b4d19bf0974a487e1f055"
          }
        },
        "633b94e846b64773a62bc1c79f602224": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8c15069d21814c8e9a1473ac69bd38a6",
            "placeholder": "​",
            "style": "IPY_MODEL_ff3068b9773b4985a9da761711576d30",
            "value": "model.safetensors: 100%"
          }
        },
        "2c9801bc180f4ef5afa41d668370d6f4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bbdbeaa66fa141e8adb06e3782c0c5c4",
            "max": 800582904,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_47aec295c0dc463ca29f718807a5d97a",
            "value": 800582904
          }
        },
        "2543180a25214e6a881093bd82e6b6e4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0c31783b92534703a07d68c6b332dd25",
            "placeholder": "​",
            "style": "IPY_MODEL_71f439379e994a858309af29f3ef6fcc",
            "value": " 801M/801M [00:01&lt;00:00, 252MB/s]"
          }
        },
        "0709f861b26b4d19bf0974a487e1f055": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8c15069d21814c8e9a1473ac69bd38a6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ff3068b9773b4985a9da761711576d30": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "bbdbeaa66fa141e8adb06e3782c0c5c4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "47aec295c0dc463ca29f718807a5d97a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "0c31783b92534703a07d68c6b332dd25": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "71f439379e994a858309af29f3ef6fcc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "08aef58b3d274e038e9609624fd73797": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_4ec76de4d3b5468c854bad5e8d4ec646",
              "IPY_MODEL_3ec31e2531d04c9291e5d26ba4a26833",
              "IPY_MODEL_5e79bb5928d04160847b6fbb0ab2d180"
            ],
            "layout": "IPY_MODEL_b0d857bbf537479388c3a16404f50f30"
          }
        },
        "4ec76de4d3b5468c854bad5e8d4ec646": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d9e5359ea8d64459826b650c01d60344",
            "placeholder": "​",
            "style": "IPY_MODEL_49c8c8f708e945578a7d7287a3d0302c",
            "value": "model.safetensors: 100%"
          }
        },
        "3ec31e2531d04c9291e5d26ba4a26833": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2ef81424ec184196be0ba015df797dc7",
            "max": 266748382,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_4ccdaf89f0e74749929e1bac57628bde",
            "value": 266748382
          }
        },
        "5e79bb5928d04160847b6fbb0ab2d180": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4bcd9a7a62ed4426b037f8c59f99da90",
            "placeholder": "​",
            "style": "IPY_MODEL_3b98393925574699b9d14b54ecd8aad8",
            "value": " 267M/267M [00:00&lt;00:00, 508MB/s]"
          }
        },
        "b0d857bbf537479388c3a16404f50f30": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d9e5359ea8d64459826b650c01d60344": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "49c8c8f708e945578a7d7287a3d0302c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2ef81424ec184196be0ba015df797dc7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4ccdaf89f0e74749929e1bac57628bde": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "4bcd9a7a62ed4426b037f8c59f99da90": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3b98393925574699b9d14b54ecd8aad8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install ultralytics"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-04-03T18:18:14.989361Z",
          "iopub.execute_input": "2025-04-03T18:18:14.989659Z",
          "iopub.status.idle": "2025-04-03T18:18:20.798236Z",
          "shell.execute_reply.started": "2025-04-03T18:18:14.989627Z",
          "shell.execute_reply": "2025-04-03T18:18:20.797295Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "THu0optoH_3H",
        "outputId": "56d28e82-fb12-4601-f54a-8215a816b550"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting ultralytics\n",
            "  Downloading ultralytics-8.3.102-py3-none-any.whl.metadata (37 kB)\n",
            "Requirement already satisfied: numpy<=2.1.1,>=1.23.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (2.0.2)\n",
            "Requirement already satisfied: matplotlib>=3.3.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (3.10.0)\n",
            "Requirement already satisfied: opencv-python>=4.6.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (4.11.0.86)\n",
            "Requirement already satisfied: pillow>=7.1.2 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (11.1.0)\n",
            "Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (6.0.2)\n",
            "Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (2.32.3)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (1.14.1)\n",
            "Requirement already satisfied: torch>=1.8.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (2.6.0+cu124)\n",
            "Requirement already satisfied: torchvision>=0.9.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (0.21.0+cu124)\n",
            "Requirement already satisfied: tqdm>=4.64.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (4.67.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from ultralytics) (5.9.5)\n",
            "Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.11/dist-packages (from ultralytics) (9.0.0)\n",
            "Requirement already satisfied: pandas>=1.1.4 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (2.2.2)\n",
            "Requirement already satisfied: seaborn>=0.11.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (0.13.2)\n",
            "Collecting ultralytics-thop>=2.0.0 (from ultralytics)\n",
            "  Downloading ultralytics_thop-2.0.14-py3-none-any.whl.metadata (9.4 kB)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (4.56.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (24.2)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.1.4->ultralytics) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.1.4->ultralytics) (2025.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (2025.1.31)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (4.13.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (2025.3.2)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.8.0->ultralytics) (1.3.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.17.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.8.0->ultralytics) (3.0.2)\n",
            "Downloading ultralytics-8.3.102-py3-none-any.whl (993 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m993.8/993.8 kB\u001b[0m \u001b[31m44.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m43.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m72.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m24.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m35.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m96.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ultralytics_thop-2.0.14-py3-none-any.whl (26 kB)\n",
            "Installing collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, ultralytics-thop, ultralytics\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 ultralytics-8.3.102 ultralytics-thop-2.0.14\n"
          ]
        }
      ],
      "execution_count": 1
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.upload()  # Manually upload `kaggle.json`"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        },
        "id": "kn3nxntAIFr3",
        "outputId": "5bb653d0-4445-41cb-a711-c31a0060d2f7"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-b8b5c6c6-5821-4e56-bc6f-be2c5f3f8c02\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-b8b5c6c6-5821-4e56-bc6f-be2c5f3f8c02\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving kaggle.json to kaggle.json\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'kaggle.json': b'{\"username\":\"f4saken\",\"key\":\"3e950e6cf11c7fe39797cd9d2104db6b\"}'}"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir -p ~/.kaggle\n",
        "!mv kaggle.json ~/.kaggle/\n",
        "!chmod 600 ~/.kaggle/kaggle.json"
      ],
      "metadata": {
        "id": "aFSv53njINUE"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import kagglehub\n",
        "aiml_gc_2025_path = kagglehub.competition_download('aiml-gc-2025')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7L3UAwNLIS5Y",
        "outputId": "7a9b73b2-9290-402b-af78-1216573c97c6"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading from https://www.kaggle.com/api/v1/competitions/data/download-all/aiml-gc-2025...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1.06G/1.06G [00:49<00:00, 22.8MB/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting files...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "\n",
        "destination = \"/content/aiml-gc-2025\"\n",
        "shutil.move(aiml_gc_2025_path, destination)\n",
        "print(f\"Files moved to: {destination}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zlcoxNRgIUtx",
        "outputId": "ca0e3224-2475-4a29-ca3b-9e50fc6b1c61"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files moved to: /content/aiml-gc-2025\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.models as models\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from ultralytics import YOLO\n",
        "from PIL import Image\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from torch.optim.lr_scheduler import CosineAnnealingWarmRestarts\n",
        "import albumentations as A\n",
        "from albumentations.pytorch import ToTensorV2\n",
        "import timm\n",
        "from torch.cuda.amp import GradScaler, autocast\n",
        "import random\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-04-03T18:18:20.799110Z",
          "iopub.execute_input": "2025-04-03T18:18:20.799350Z",
          "iopub.status.idle": "2025-04-03T18:18:35.887710Z",
          "shell.execute_reply.started": "2025-04-03T18:18:20.799328Z",
          "shell.execute_reply": "2025-04-03T18:18:35.886810Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jo1fKHR_H_3I",
        "outputId": "74b0eca3-6b65-423c-fd7d-a3cbe6a0a4e3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Creating new Ultralytics Settings v0.0.6 file ✅ \n",
            "View Ultralytics Settings with 'yolo settings' or at '/root/.config/Ultralytics/settings.json'\n",
            "Update Settings with 'yolo settings key=value', i.e. 'yolo settings runs_dir=path/to/dir'. For help see https://docs.ultralytics.com/quickstart/#ultralytics-settings.\n"
          ]
        }
      ],
      "execution_count": 6
    },
    {
      "cell_type": "code",
      "source": [
        "# Set seeds for reproducibility\n",
        "def seed_everything(seed=42):\n",
        "    random.seed(seed)\n",
        "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed(seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "\n",
        "seed_everything()"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-04-03T18:18:35.891247Z",
          "iopub.execute_input": "2025-04-03T18:18:35.891443Z",
          "iopub.status.idle": "2025-04-03T18:18:35.902085Z",
          "shell.execute_reply.started": "2025-04-03T18:18:35.891425Z",
          "shell.execute_reply": "2025-04-03T18:18:35.901523Z"
        },
        "id": "C8otxvtoH_3J"
      },
      "outputs": [],
      "execution_count": 7
    },
    {
      "cell_type": "code",
      "source": [
        "# Create result directories\n",
        "os.makedirs(\"/content/working/data/\", exist_ok=True)\n",
        "os.makedirs(\"/content/working/models/\", exist_ok=True)\n",
        "\n",
        "# Initialize YOLO model with the latest version (YOLOv8x)\n",
        "model_yolo = YOLO('yolov8x.pt')\n",
        "\n",
        "# Paths\n",
        "train_path = '/content/aiml-gc-2025/AI-ML GC 2025 Dataset/train'\n",
        "test_path = \"/content/aiml-gc-2025/AI-ML GC 2025 Dataset/test\"\n",
        "\n",
        "train_folders = os.listdir(train_path)\n",
        "le = LabelEncoder()"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-04-03T18:18:35.902796Z",
          "iopub.execute_input": "2025-04-03T18:18:35.903094Z",
          "iopub.status.idle": "2025-04-03T18:18:37.419225Z",
          "shell.execute_reply.started": "2025-04-03T18:18:35.903065Z",
          "shell.execute_reply": "2025-04-03T18:18:37.418303Z"
        },
        "id": "PnT5CD_9H_3J",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fc366251-43e3-4279-e70b-e6fa10ff2d98"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolov8x.pt to 'yolov8x.pt'...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 131M/131M [00:00<00:00, 492MB/s] \n"
          ]
        }
      ],
      "execution_count": 8
    },
    {
      "cell_type": "code",
      "source": [
        "# Enhanced bird detection and cropping with padding and confidence thresholds\n",
        "def detect_and_crop(file_path, folder=None, is_train=True):\n",
        "    \"\"\"\n",
        "    Enhanced detection and cropping with better padding and handling of edge cases.\n",
        "    Implements dynamic padding based on bird size and aspect ratio preservation.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        image = Image.open(file_path).convert('RGB')\n",
        "        image_np = np.array(image)\n",
        "        orig_height, orig_width = image_np.shape[:2]\n",
        "\n",
        "        # Run YOLOv8 detection with higher confidence threshold for precision\n",
        "        results = model_yolo(image_np, verbose=False, conf=0.25, classes=[14, 15, 16, 17, 18, 19])  # Bird-related classes\n",
        "\n",
        "        best_box = None\n",
        "        best_conf = 0\n",
        "\n",
        "        for result in results:\n",
        "            for i, box in enumerate(result.boxes.xyxy):\n",
        "                # Get confidence score\n",
        "                conf = result.boxes.conf[i].item()\n",
        "\n",
        "                if conf > best_conf:\n",
        "                    best_conf = conf\n",
        "                    best_box = box\n",
        "\n",
        "        if best_box is not None:\n",
        "            x1, y1, x2, y2 = map(int, best_box[:4])\n",
        "\n",
        "            # Calculate padding (30% of the bird size, dynamic)\n",
        "            width, height = x2 - x1, y2 - y1\n",
        "            pad_x = int(width * 0.3)\n",
        "            pad_y = int(height * 0.3)\n",
        "\n",
        "            # Apply padding with boundary checks\n",
        "            x1 = max(0, x1 - pad_x)\n",
        "            y1 = max(0, y1 - pad_y)\n",
        "            x2 = min(orig_width, x2 + pad_x)\n",
        "            y2 = min(orig_height, y2 + pad_y)\n",
        "\n",
        "            cropped_img = image_np[y1:y2, x1:x2]\n",
        "\n",
        "            if cropped_img.size == 0:\n",
        "                # Fallback to original image if crop failed\n",
        "                cropped_img = image_np\n",
        "        else:\n",
        "            # No detection - use original image\n",
        "            cropped_img = image_np\n",
        "\n",
        "        cropped_img = Image.fromarray(cropped_img)\n",
        "\n",
        "        # Keep aspect ratio when resizing\n",
        "        if is_train:\n",
        "            cropped_img = cropped_img.resize((384, 384), Image.LANCZOS)  # Adjusted size for transformers\n",
        "            save_path = f\"/content/working/data/{folder}_{os.path.basename(file_path)}\"\n",
        "            cropped_img.save(save_path)\n",
        "            return save_path\n",
        "        else:\n",
        "            cropped_img = cropped_img.resize((384, 384), Image.LANCZOS)  # Adjusted size for transformers\n",
        "            return cropped_img\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error processing {file_path}: {e}\")\n",
        "        # Return original image in case of error\n",
        "        if is_train:\n",
        "            image = Image.open(file_path).convert('RGB')\n",
        "            image = image.resize((384, 384), Image.LANCZOS)  # Adjusted size for transformers\n",
        "            save_path = f\"/content/working/data/{folder}_{os.path.basename(file_path)}\"\n",
        "            image.save(save_path)\n",
        "            return save_path\n",
        "        else:\n",
        "            return Image.open(file_path).convert('RGB').resize((384, 384), Image.LANCZOS)  # Adjusted size for transformers\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-04-03T18:18:37.420042Z",
          "iopub.execute_input": "2025-04-03T18:18:37.420339Z",
          "iopub.status.idle": "2025-04-03T18:18:37.430311Z",
          "shell.execute_reply.started": "2025-04-03T18:18:37.420316Z",
          "shell.execute_reply": "2025-04-03T18:18:37.429155Z"
        },
        "id": "2xuHlVuCH_3J"
      },
      "outputs": [],
      "execution_count": 9
    },
    {
      "cell_type": "code",
      "source": [
        "# Process and prepare dataset\n",
        "print(\"Preparing dataset...\")\n",
        "image_paths = []\n",
        "labels = []\n",
        "\n",
        "for folder in tqdm(train_folders, desc=\"Processing Folders\"):\n",
        "    train_files = os.listdir(os.path.join(train_path, folder))\n",
        "    for file in train_files:\n",
        "        file_path = os.path.join(train_path, folder, file)\n",
        "        save_path = detect_and_crop(file_path, folder)\n",
        "        image_paths.append(save_path)\n",
        "        labels.append(folder)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-04-03T18:18:37.603006Z",
          "iopub.execute_input": "2025-04-03T18:18:37.603455Z",
          "execution_failed": "2025-04-03T18:24:54.443Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "td_3NjUlH_3K",
        "outputId": "8f7d4374-a798-4e9f-a829-aefea81b6570"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Preparing dataset...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing Folders: 100%|██████████| 200/200 [04:09<00:00,  1.25s/it]\n"
          ]
        }
      ],
      "execution_count": 10
    },
    {
      "cell_type": "code",
      "source": [
        "# Encode labels\n",
        "le.fit(labels)\n",
        "labels = le.transform(labels)\n",
        "\n",
        "# Create stratified folds for cross-validation\n",
        "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "# Convert to numpy arrays for easier handling\n",
        "image_paths = np.array(image_paths)\n",
        "labels = np.array(labels)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-04-03T18:12:43.557450Z",
          "iopub.execute_input": "2025-04-03T18:12:43.557772Z",
          "iopub.status.idle": "2025-04-03T18:12:43.574084Z",
          "shell.execute_reply.started": "2025-04-03T18:12:43.557740Z",
          "shell.execute_reply": "2025-04-03T18:12:43.573459Z"
        },
        "id": "_tTNQkuaH_3K"
      },
      "outputs": [],
      "execution_count": 11
    },
    {
      "cell_type": "code",
      "source": [
        "# Advanced augmentations using Albumentations\n",
        "train_transforms = A.Compose([\n",
        "    A.RandomResizedCrop(size=(384, 384), scale=(0.8, 1.0)),\n",
        "    A.OneOf([\n",
        "        A.RandomRotate90(),\n",
        "        A.Rotate(limit=40),\n",
        "    ], p=0.5),\n",
        "    A.OneOf([\n",
        "        A.RandomBrightnessContrast(brightness_limit=0.2, contrast_limit=0.2),\n",
        "        A.HueSaturationValue(hue_shift_limit=20, sat_shift_limit=30, val_shift_limit=20),\n",
        "        A.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),\n",
        "    ], p=0.5),\n",
        "    A.OneOf([\n",
        "        A.GaussianBlur(blur_limit=3),\n",
        "        A.MedianBlur(blur_limit=3),\n",
        "        A.MotionBlur(blur_limit=3),\n",
        "    ], p=0.3),\n",
        "    A.CoarseDropout(max_holes=8, max_height=64, max_width=64, min_holes=1, min_height=32, min_width=32, p=0.3),\n",
        "    A.GaussNoise(var_limit=(10.0, 50.0), p=0.2),\n",
        "    A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "    ToTensorV2(),\n",
        "])\n",
        "\n",
        "val_transforms = A.Compose([\n",
        "    A.Resize(height=384, width=384),\n",
        "    A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "    ToTensorV2(),\n",
        "])"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-04-03T18:12:43.575825Z",
          "iopub.execute_input": "2025-04-03T18:12:43.576071Z",
          "iopub.status.idle": "2025-04-03T18:12:43.593930Z",
          "shell.execute_reply.started": "2025-04-03T18:12:43.576051Z",
          "shell.execute_reply": "2025-04-03T18:12:43.593219Z"
        },
        "id": "Tbr4vdGMH_3L"
      },
      "outputs": [],
      "execution_count": 12
    },
    {
      "cell_type": "code",
      "source": [
        "# Enhanced Dataset Class\n",
        "class BirdDataset(Dataset):\n",
        "    def __init__(self, image_paths, labels=None, transform=None, is_test=False):\n",
        "        self.image_paths = image_paths\n",
        "        self.labels = labels\n",
        "        self.transform = transform\n",
        "        self.is_test = is_test\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.image_paths)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_path = self.image_paths[idx]\n",
        "\n",
        "        image = Image.open(img_path).convert('RGB')\n",
        "        image = np.array(image)\n",
        "\n",
        "        if self.transform:\n",
        "            image = self.transform(image=image)['image']\n",
        "\n",
        "        if self.is_test:\n",
        "            return image\n",
        "        else:\n",
        "            label = self.labels[idx]\n",
        "            return image, torch.tensor(label)# ViT-based model with transformer architecture"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-04-03T18:12:43.595016Z",
          "iopub.execute_input": "2025-04-03T18:12:43.595288Z",
          "iopub.status.idle": "2025-04-03T18:12:43.612020Z",
          "shell.execute_reply.started": "2025-04-03T18:12:43.595260Z",
          "shell.execute_reply": "2025-04-03T18:12:43.611347Z"
        },
        "id": "4_ETPSrVH_3L"
      },
      "outputs": [],
      "execution_count": 13
    },
    {
      "cell_type": "code",
      "source": [
        "# ViT-based model with transformer architecture\n",
        "def create_vit_model(num_classes=200):\n",
        "    \"\"\"\n",
        "    Creates a Vision Transformer model with pretrained weights\n",
        "    \"\"\"\n",
        "    # Using ViT-Large model\n",
        "    model = timm.create_model('vit_large_patch16_384', pretrained=True)\n",
        "\n",
        "    # Freeze early layers for better transfer learning\n",
        "    ct = 0\n",
        "    for name, param in model.named_parameters():\n",
        "        if ct < 150:  # Freeze first 150 parameters\n",
        "            param.requires_grad = False\n",
        "        ct += 1\n",
        "\n",
        "    # Modify the head for bird classification\n",
        "    in_features = model.head.in_features\n",
        "    model.head = nn.Sequential(\n",
        "        nn.LayerNorm(in_features),\n",
        "        nn.Linear(in_features, 1024),\n",
        "        nn.GELU(),\n",
        "        nn.Dropout(0.2),\n",
        "        nn.Linear(1024, num_classes)\n",
        "    )\n",
        "\n",
        "    return model"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-04-03T18:12:43.612775Z",
          "iopub.execute_input": "2025-04-03T18:12:43.613079Z",
          "iopub.status.idle": "2025-04-03T18:12:43.630421Z",
          "shell.execute_reply.started": "2025-04-03T18:12:43.613050Z",
          "shell.execute_reply": "2025-04-03T18:12:43.629736Z"
        },
        "id": "fVLfnrxwH_3L"
      },
      "outputs": [],
      "execution_count": 14
    },
    {
      "cell_type": "code",
      "source": [
        "# Swin Transformer model\n",
        "def create_swin_model(num_classes=200):\n",
        "    \"\"\"\n",
        "    Creates a Swin Transformer model with pretrained weights\n",
        "    \"\"\"\n",
        "    model = timm.create_model('swin_large_patch4_window12_384', pretrained=True)\n",
        "\n",
        "    # Freeze early layers\n",
        "    ct = 0\n",
        "    for name, param in model.named_parameters():\n",
        "        if ct < 150:  # Freeze first 150 parameters\n",
        "            param.requires_grad = False\n",
        "        ct += 1\n",
        "\n",
        "    # Modify the head\n",
        "    in_features = model.head.in_features\n",
        "    model.head = nn.Sequential(\n",
        "        nn.LayerNorm(in_features),\n",
        "        nn.Linear(in_features, 1024),\n",
        "        nn.GELU(),\n",
        "        nn.Dropout(0.2),\n",
        "        nn.Linear(1024, num_classes)\n",
        "    )\n",
        "\n",
        "    return model\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-04-03T18:12:43.631169Z",
          "iopub.execute_input": "2025-04-03T18:12:43.631360Z",
          "iopub.status.idle": "2025-04-03T18:12:43.653035Z",
          "shell.execute_reply.started": "2025-04-03T18:12:43.631343Z",
          "shell.execute_reply": "2025-04-03T18:12:43.652143Z"
        },
        "id": "NVNefI2jH_3M"
      },
      "outputs": [],
      "execution_count": 15
    },
    {
      "cell_type": "code",
      "source": [
        "# Advanced ConvNeXt model (transformer-inspired architecture)\n",
        "def create_convnext_model(num_classes=200):\n",
        "    \"\"\"\n",
        "    Creates a ConvNeXt model which incorporates transformer design principles\n",
        "    into a convolutional network\n",
        "    \"\"\"\n",
        "    model = timm.create_model('convnext_large', pretrained=True)\n",
        "\n",
        "    # Freeze early layers\n",
        "    ct = 0\n",
        "    for name, param in model.named_parameters():\n",
        "        if ct < 150:\n",
        "            param.requires_grad = False\n",
        "        ct += 1\n",
        "\n",
        "    # Modify the head\n",
        "    in_features = model.head.fc.in_features\n",
        "    model.head.fc = nn.Sequential(\n",
        "        nn.LayerNorm(in_features),\n",
        "        nn.Linear(in_features, 1024),\n",
        "        nn.GELU(),\n",
        "        nn.Dropout(0.2),\n",
        "        nn.Linear(1024, num_classes)\n",
        "    )\n",
        "\n",
        "    return model"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-04-03T18:12:43.653826Z",
          "iopub.execute_input": "2025-04-03T18:12:43.654087Z",
          "iopub.status.idle": "2025-04-03T18:12:43.668891Z",
          "shell.execute_reply.started": "2025-04-03T18:12:43.654058Z",
          "shell.execute_reply": "2025-04-03T18:12:43.668080Z"
        },
        "id": "ZvemDH_nH_3M"
      },
      "outputs": [],
      "execution_count": 16
    },
    {
      "cell_type": "code",
      "source": [
        "def create_efficientnet_model(num_classes=200):\n",
        "    \"\"\"\n",
        "    Creates an EfficientNet-B7 model with pretrained weights.\n",
        "    It freezes the first 150 parameters and replaces the classification head.\n",
        "    \"\"\"\n",
        "    # Create an EfficientNet-B7 model with pretrained weights.\n",
        "    model = timm.create_model('tf_efficientnet_b7_ns', pretrained=True)\n",
        "\n",
        "    # Freeze early layers: iterate over parameters and freeze the first 150.\n",
        "    ct = 0\n",
        "    for name, param in model.named_parameters():\n",
        "        if ct < 150:\n",
        "            param.requires_grad = False\n",
        "        ct += 1\n",
        "\n",
        "    # Modify the classifier head.\n",
        "    # Retrieve the input features for the classifier.\n",
        "    in_features = model.get_classifier().in_features\n",
        "    # Replace the classifier with a custom head.\n",
        "    model.classifier = nn.Sequential(\n",
        "        nn.LayerNorm(in_features),\n",
        "        nn.Linear(in_features, 1024),\n",
        "        nn.GELU(),\n",
        "        nn.Dropout(0.2),\n",
        "        nn.Linear(1024, num_classes)\n",
        "    )\n",
        "\n",
        "    return model"
      ],
      "metadata": {
        "id": "ZCOgCYhIIg8F"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Custom model ensemble\n",
        "class ModelEnsemble(nn.Module):\n",
        "    def __init__(self, models):\n",
        "        super(ModelEnsemble, self).__init__()\n",
        "        self.models = nn.ModuleList(models)\n",
        "\n",
        "    def forward(self, x):\n",
        "        outputs = [model(x) for model in self.models]\n",
        "        return torch.mean(torch.stack(outputs), dim=0)\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-04-03T18:12:43.670887Z",
          "iopub.execute_input": "2025-04-03T18:12:43.671136Z",
          "iopub.status.idle": "2025-04-03T18:12:43.687098Z",
          "shell.execute_reply.started": "2025-04-03T18:12:43.671117Z",
          "shell.execute_reply": "2025-04-03T18:12:43.686184Z"
        },
        "id": "k4soPZhDH_3M"
      },
      "outputs": [],
      "execution_count": 18
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Training function with mixed precision\n",
        "def train_model(model, train_loader, val_loader, criterion, optimizer, scheduler, device, model_name, num_epochs=10):\n",
        "    best_val_acc = 0.0\n",
        "    scaler = GradScaler()  # For mixed precision training\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        # Training phase\n",
        "        model.train()\n",
        "        running_loss = 0.0\n",
        "        correct = 0\n",
        "        total = 0\n",
        "\n",
        "        train_bar = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{num_epochs}\")\n",
        "        for batch_idx, (images, labels) in enumerate(train_bar):\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            # Mixed precision training\n",
        "            with autocast():\n",
        "                outputs = model(images)\n",
        "                loss = criterion(outputs, labels)\n",
        "\n",
        "            scaler.scale(loss).backward()\n",
        "            scaler.step(optimizer)\n",
        "            scaler.update()\n",
        "\n",
        "            running_loss += loss.item()\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "\n",
        "            train_bar.set_postfix(loss=running_loss/(batch_idx+1), acc=f\"{100.0*correct/total:.2f}%\")\n",
        "\n",
        "        train_acc = 100.0 * correct / total\n",
        "        print(f\"Epoch {epoch+1}, Loss: {running_loss/len(train_loader):.4f}, Accuracy: {train_acc:.2f}%\")\n",
        "\n",
        "        # Validation phase\n",
        "        model.eval()\n",
        "        val_loss = 0.0\n",
        "        correct = 0\n",
        "        total = 0\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for images, labels in tqdm(val_loader, desc=\"Validation\"):\n",
        "                images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "                outputs = model(images)\n",
        "                loss = criterion(outputs, labels)\n",
        "\n",
        "                val_loss += loss.item()\n",
        "                _, predicted = torch.max(outputs.data, 1)\n",
        "                total += labels.size(0)\n",
        "                correct += (predicted == labels).sum().item()\n",
        "\n",
        "        val_acc = 100.0 * correct / total\n",
        "        print(f\"Validation Loss: {val_loss/len(val_loader):.4f}, Accuracy: {val_acc:.2f}%\")\n",
        "\n",
        "        # Update scheduler\n",
        "        scheduler.step()\n",
        "\n",
        "        # Save best model\n",
        "        if val_acc > best_val_acc:\n",
        "            best_val_acc = val_acc\n",
        "            torch.save(model.state_dict(), f\"/content/working/models/best_{model_name}_epoch_{epoch}.pth\")\n",
        "            print(f\"Best model saved with accuracy: {best_val_acc:.2f}%\")\n",
        "\n",
        "    return model"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-04-03T18:12:43.688252Z",
          "iopub.execute_input": "2025-04-03T18:12:43.688556Z",
          "iopub.status.idle": "2025-04-03T18:12:43.705555Z",
          "shell.execute_reply.started": "2025-04-03T18:12:43.688527Z",
          "shell.execute_reply": "2025-04-03T18:12:43.704719Z"
        },
        "id": "ssFVh9oXH_3N"
      },
      "outputs": [],
      "execution_count": 19
    },
    {
      "cell_type": "code",
      "source": [
        "# Test Time Augmentation (TTA)\n",
        "def tta_inference(model, image, device, transforms_list):\n",
        "    \"\"\"\n",
        "    Performs Test Time Augmentation by averaging predictions from\n",
        "    multiple augmented versions of the input image\n",
        "    \"\"\"\n",
        "    model.eval()\n",
        "    predictions = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        # Original image\n",
        "        outputs = model(image)\n",
        "        predictions.append(outputs)\n",
        "\n",
        "        # Horizontally flipped image\n",
        "        flipped_image = torch.flip(image, dims=[3])\n",
        "        outputs = model(flipped_image)\n",
        "        predictions.append(outputs)\n",
        "\n",
        "        # Vertically flipped image\n",
        "        flipped_image = torch.flip(image, dims=[2])\n",
        "        outputs = model(flipped_image)\n",
        "        predictions.append(outputs)\n",
        "\n",
        "        # Both flipped\n",
        "        flipped_image = torch.flip(image, dims=[2, 3])\n",
        "        outputs = model(flipped_image)\n",
        "        predictions.append(outputs)\n",
        "\n",
        "    # Average predictions\n",
        "    return torch.mean(torch.stack(predictions), dim=0)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-04-03T18:12:43.706389Z",
          "iopub.execute_input": "2025-04-03T18:12:43.706709Z",
          "iopub.status.idle": "2025-04-03T18:12:43.725828Z",
          "shell.execute_reply.started": "2025-04-03T18:12:43.706681Z",
          "shell.execute_reply": "2025-04-03T18:12:43.725154Z"
        },
        "id": "fZ0J_kDKH_3N"
      },
      "outputs": [],
      "execution_count": 20
    },
    {
      "cell_type": "code",
      "source": [
        "# Set device\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "# Define hyperparameters\n",
        "batch_size = 16\n",
        "num_epochs = 10\n",
        "\n",
        "# Using stratified cross-validation\n",
        "models = []"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-04-03T18:12:43.726492Z",
          "iopub.execute_input": "2025-04-03T18:12:43.726678Z",
          "iopub.status.idle": "2025-04-03T18:12:43.745222Z",
          "shell.execute_reply.started": "2025-04-03T18:12:43.726661Z",
          "shell.execute_reply": "2025-04-03T18:12:43.744481Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e5irVskAH_3N",
        "outputId": "2836ad5e-a8b7-4769-88f7-b98554699127"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n"
          ]
        }
      ],
      "execution_count": 21
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "train_images, val_images, train_labels, val_labels = train_test_split(\n",
        "    image_paths, labels, test_size=0.1, stratify=labels, random_state=42\n",
        ")"
      ],
      "metadata": {
        "id": "lhmj-ZWKv53n"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create datasets\n",
        "train_dataset = BirdDataset(\n",
        "    train_images,\n",
        "    train_labels,\n",
        "    transform=train_transforms\n",
        ")\n",
        "\n",
        "val_dataset = BirdDataset(\n",
        "    val_images,\n",
        "    val_labels,\n",
        "    transform=val_transforms\n",
        ")\n",
        "\n",
        "# Create dataloaders\n",
        "train_loader = DataLoader(\n",
        "    train_dataset,\n",
        "    batch_size=batch_size,\n",
        "    shuffle=True,\n",
        "    num_workers=4,\n",
        "    pin_memory=True\n",
        ")\n",
        "\n",
        "val_loader = DataLoader(\n",
        "    val_dataset,\n",
        "    batch_size=batch_size,\n",
        "    shuffle=False,\n",
        "    num_workers=4,\n",
        "    pin_memory=True\n",
        ")"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-04-03T18:12:43.746180Z",
          "iopub.execute_input": "2025-04-03T18:12:43.746454Z",
          "iopub.status.idle": "2025-04-03T18:15:25.689814Z",
          "shell.execute_reply.started": "2025-04-03T18:12:43.746426Z",
          "shell.execute_reply": "2025-04-03T18:15:25.688568Z"
        },
        "id": "CIlRLPABH_3O"
      },
      "outputs": [],
      "execution_count": 57
    },
    {
      "cell_type": "code",
      "source": [
        "# Train each model separately\n",
        "models = []\n",
        "model_types = [\"vit\", \"convnext\"]\n",
        "\n",
        "for model_type in model_types:\n",
        "    print(f\"\\nTraining {model_type} model\")\n",
        "\n",
        "    # Create model based on type\n",
        "    if model_type == \"vit\":\n",
        "        model = create_vit_model(num_classes=200)\n",
        "    elif model_type == \"swin\":\n",
        "        model = create_swin_model(num_classes=200)\n",
        "    else:  # convnext\n",
        "        model = create_convnext_model(num_classes=200)\n",
        "\n",
        "    model = model.to(device)\n",
        "\n",
        "    # Use label smoothing cross entropy loss\n",
        "    criterion = nn.CrossEntropyLoss(label_smoothing=0.1)\n",
        "\n",
        "    # Use AdamW optimizer with weight decay and different learning rates for different parts\n",
        "    # Higher learning rate for newly added layers\n",
        "    params = [\n",
        "        {'params': [p for n, p in model.named_parameters() if 'head' not in n], 'lr': 1e-5},\n",
        "        {'params': [p for n, p in model.named_parameters() if 'head' in n], 'lr': 1e-4}\n",
        "    ]\n",
        "\n",
        "    optimizer = optim.AdamW(params, weight_decay=1e-5)\n",
        "\n",
        "    # Use cosine annealing scheduler\n",
        "    scheduler = CosineAnnealingWarmRestarts(optimizer, T_0=5, T_mult=1, eta_min=1e-6)\n",
        "    try:\n",
        "      # Train model\n",
        "      model = train_model(\n",
        "          model,\n",
        "          train_loader,\n",
        "          val_loader,\n",
        "          criterion,\n",
        "          optimizer,\n",
        "          scheduler,\n",
        "          device,\n",
        "          model_type,\n",
        "          num_epochs=num_epochs\n",
        "      )\n",
        "    except:\n",
        "      continue\n",
        "\n",
        "    # Save the trained model\n",
        "    torch.save(model.state_dict(), f\"/content/working/models/{model_type}_model.pth\")\n",
        "    models.append(model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "8d4009274f9f489a83bbe9ee023fc29a",
            "633b94e846b64773a62bc1c79f602224",
            "2c9801bc180f4ef5afa41d668370d6f4",
            "2543180a25214e6a881093bd82e6b6e4",
            "0709f861b26b4d19bf0974a487e1f055",
            "8c15069d21814c8e9a1473ac69bd38a6",
            "ff3068b9773b4985a9da761711576d30",
            "bbdbeaa66fa141e8adb06e3782c0c5c4",
            "47aec295c0dc463ca29f718807a5d97a",
            "0c31783b92534703a07d68c6b332dd25",
            "71f439379e994a858309af29f3ef6fcc"
          ]
        },
        "id": "ybBAtSj9udJO",
        "outputId": "b93926d7-a718-4712-de73-858b91502757"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Training vit model\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/10: 100%|██████████| 559/559 [01:02<00:00,  8.96it/s, acc=59.16%, loss=2.48]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Loss: 2.4822, Accuracy: 59.16%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 30/30 [00:10<00:00,  2.82it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 1.3280, Accuracy: 84.93%\n",
            "Best model saved with accuracy: 84.93%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2/10: 100%|██████████| 559/559 [01:02<00:00,  8.99it/s, acc=84.99%, loss=1.35]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2, Loss: 1.3497, Accuracy: 84.99%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 30/30 [00:10<00:00,  2.82it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 1.2239, Accuracy: 89.60%\n",
            "Best model saved with accuracy: 89.60%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 3/10: 100%|██████████| 559/559 [01:02<00:00,  8.98it/s, acc=89.38%, loss=1.22]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3, Loss: 1.2191, Accuracy: 89.38%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 30/30 [00:10<00:00,  2.81it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 1.1617, Accuracy: 91.93%\n",
            "Best model saved with accuracy: 91.93%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 4/10: 100%|██████████| 559/559 [01:02<00:00,  8.98it/s, acc=92.24%, loss=1.14]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4, Loss: 1.1436, Accuracy: 92.24%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 30/30 [00:10<00:00,  2.81it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 1.1505, Accuracy: 92.14%\n",
            "Best model saved with accuracy: 92.14%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 5/10: 100%|██████████| 559/559 [01:02<00:00,  8.99it/s, acc=93.25%, loss=1.11]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5, Loss: 1.1111, Accuracy: 93.25%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 30/30 [00:10<00:00,  2.83it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 1.1438, Accuracy: 92.36%\n",
            "Best model saved with accuracy: 92.36%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 6/10: 100%|██████████| 559/559 [01:02<00:00,  8.97it/s, acc=91.86%, loss=1.15]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 6, Loss: 1.1512, Accuracy: 91.86%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 30/30 [00:10<00:00,  2.82it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 1.1585, Accuracy: 91.08%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 7/10: 100%|██████████| 559/559 [01:02<00:00,  9.00it/s, acc=93.57%, loss=1.11]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 7, Loss: 1.1057, Accuracy: 93.57%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 30/30 [00:10<00:00,  2.82it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 1.1596, Accuracy: 91.93%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 8/10: 100%|██████████| 559/559 [01:02<00:00,  9.01it/s, acc=95.15%, loss=1.05]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 8, Loss: 1.0460, Accuracy: 95.15%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 30/30 [00:10<00:00,  2.81it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 1.1512, Accuracy: 92.36%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 9/10: 100%|██████████| 559/559 [01:02<00:00,  8.99it/s, acc=96.31%, loss=1.01]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 9, Loss: 1.0135, Accuracy: 96.31%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 30/30 [00:10<00:00,  2.82it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 1.1519, Accuracy: 92.57%\n",
            "Best model saved with accuracy: 92.57%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 10/10: 100%|██████████| 559/559 [01:02<00:00,  8.98it/s, acc=97.25%, loss=0.99]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 10, Loss: 0.9904, Accuracy: 97.25%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 30/30 [00:10<00:00,  2.82it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 1.1494, Accuracy: 92.36%\n",
            "\n",
            "Training convnext model\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/10: 100%|██████████| 559/559 [00:56<00:00,  9.96it/s, acc=51.37%, loss=2.82]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Loss: 2.8239, Accuracy: 51.37%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 30/30 [00:06<00:00,  4.69it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 1.3547, Accuracy: 86.41%\n",
            "Best model saved with accuracy: 86.41%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2/10: 100%|██████████| 559/559 [00:55<00:00, 10.00it/s, acc=78.77%, loss=1.63]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2, Loss: 1.6322, Accuracy: 78.77%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 30/30 [00:06<00:00,  4.72it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 1.2401, Accuracy: 89.17%\n",
            "Best model saved with accuracy: 89.17%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 3/10: 100%|██████████| 559/559 [00:56<00:00,  9.97it/s, acc=83.56%, loss=1.48]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3, Loss: 1.4844, Accuracy: 83.56%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 30/30 [00:06<00:00,  4.67it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 1.1880, Accuracy: 90.66%\n",
            "Best model saved with accuracy: 90.66%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 4/10: 100%|██████████| 559/559 [00:56<00:00,  9.96it/s, acc=85.55%, loss=1.41]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4, Loss: 1.4092, Accuracy: 85.55%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 30/30 [00:06<00:00,  4.72it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 1.1784, Accuracy: 90.87%\n",
            "Best model saved with accuracy: 90.87%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 5/10: 100%|██████████| 559/559 [00:55<00:00,  9.98it/s, acc=86.26%, loss=1.38]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5, Loss: 1.3753, Accuracy: 86.26%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 30/30 [00:06<00:00,  4.70it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 1.1612, Accuracy: 91.72%\n",
            "Best model saved with accuracy: 91.72%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 6/10: 100%|██████████| 559/559 [00:55<00:00,  9.99it/s, acc=85.91%, loss=1.39]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 6, Loss: 1.3875, Accuracy: 85.91%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 30/30 [00:06<00:00,  4.72it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 1.1811, Accuracy: 90.02%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 7/10: 100%|██████████| 559/559 [00:55<00:00, 10.00it/s, acc=87.04%, loss=1.34]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 7, Loss: 1.3398, Accuracy: 87.04%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 30/30 [00:06<00:00,  4.71it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 1.1631, Accuracy: 92.57%\n",
            "Best model saved with accuracy: 92.57%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 8/10: 100%|██████████| 559/559 [00:55<00:00, 10.02it/s, acc=88.70%, loss=1.28]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 8, Loss: 1.2792, Accuracy: 88.70%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 30/30 [00:06<00:00,  4.67it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 1.1625, Accuracy: 90.87%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 9/10: 100%|██████████| 559/559 [00:55<00:00,  9.99it/s, acc=90.04%, loss=1.24]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 9, Loss: 1.2411, Accuracy: 90.04%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 30/30 [00:06<00:00,  4.70it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 1.1435, Accuracy: 91.30%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 10/10: 100%|██████████| 559/559 [00:55<00:00, 10.00it/s, acc=90.37%, loss=1.22]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 10, Loss: 1.2240, Accuracy: 90.37%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 30/30 [00:06<00:00,  4.70it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 1.1398, Accuracy: 91.51%\n",
            "\n",
            "Training swin model\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:  47%|####7     | 377M/801M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8d4009274f9f489a83bbe9ee023fc29a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/10:   0%|          | 0/559 [00:00<?, ?it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_types = [\"efficientnet\"]\n",
        "\n",
        "for model_type in model_types:\n",
        "    print(f\"\\nTraining {model_type} model\")\n",
        "\n",
        "    # Create model based on type\n",
        "    if model_type == \"vit\":\n",
        "        model = create_vit_model(num_classes=200)\n",
        "    elif model_type == \"swin\":\n",
        "        model = create_swin_model(num_classes=200)\n",
        "    elif model_type == \"efficientnet\":\n",
        "        model = create_efficientnet_model(num_classes=200)\n",
        "    else:  # convnext\n",
        "        model = create_convnext_model(num_classes=200)\n",
        "\n",
        "    model = model.to(device)\n",
        "\n",
        "    # Use label smoothing cross entropy loss\n",
        "    criterion = nn.CrossEntropyLoss(label_smoothing=0.1)\n",
        "\n",
        "    # Use AdamW optimizer with weight decay and different learning rates for different parts\n",
        "    # Higher learning rate for newly added layers\n",
        "    params = [\n",
        "        {'params': [p for n, p in model.named_parameters() if 'head' not in n], 'lr': 1e-5},\n",
        "        {'params': [p for n, p in model.named_parameters() if 'head' in n], 'lr': 1e-4}\n",
        "    ]\n",
        "\n",
        "    optimizer = optim.AdamW(params, weight_decay=1e-5)\n",
        "\n",
        "    # Use cosine annealing scheduler\n",
        "    scheduler = CosineAnnealingWarmRestarts(optimizer, T_0=5, T_mult=1, eta_min=1e-6)\n",
        "    try:\n",
        "      # Train model\n",
        "      model = train_model(\n",
        "          model,\n",
        "          train_loader,\n",
        "          val_loader,\n",
        "          criterion,\n",
        "          optimizer,\n",
        "          scheduler,\n",
        "          device,\n",
        "          model_type,\n",
        "          num_epochs=num_epochs\n",
        "      )\n",
        "    except:\n",
        "      continue\n",
        "\n",
        "    # Save the trained model\n",
        "    torch.save(model.state_dict(), f\"/content/working/models/{model_type}_model.pth\")\n",
        "    models.append(model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 933,
          "referenced_widgets": [
            "08aef58b3d274e038e9609624fd73797",
            "4ec76de4d3b5468c854bad5e8d4ec646",
            "3ec31e2531d04c9291e5d26ba4a26833",
            "5e79bb5928d04160847b6fbb0ab2d180",
            "b0d857bbf537479388c3a16404f50f30",
            "d9e5359ea8d64459826b650c01d60344",
            "49c8c8f708e945578a7d7287a3d0302c",
            "2ef81424ec184196be0ba015df797dc7",
            "4ccdaf89f0e74749929e1bac57628bde",
            "4bcd9a7a62ed4426b037f8c59f99da90",
            "3b98393925574699b9d14b54ecd8aad8"
          ]
        },
        "id": "NWXbaEEoHtb_",
        "outputId": "d41e49e3-5e1d-4110-bfe6-c47d1c46b731"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Training efficientnet model\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/267M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "08aef58b3d274e038e9609624fd73797"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/10: 100%|██████████| 559/559 [01:17<00:00,  7.22it/s, acc=12.10%, loss=4.93]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Loss: 4.9329, Accuracy: 12.10%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 30/30 [00:02<00:00, 12.94it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 4.0331, Accuracy: 37.58%\n",
            "Best model saved with accuracy: 37.58%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2/10: 100%|██████████| 559/559 [01:16<00:00,  7.33it/s, acc=42.76%, loss=3.47]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2, Loss: 3.4735, Accuracy: 42.76%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 30/30 [00:02<00:00, 13.40it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 2.4060, Accuracy: 68.79%\n",
            "Best model saved with accuracy: 68.79%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 3/10: 100%|██████████| 559/559 [01:18<00:00,  7.16it/s, acc=64.70%, loss=2.39]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3, Loss: 2.3875, Accuracy: 64.70%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 30/30 [00:02<00:00, 13.08it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 1.8681, Accuracy: 78.13%\n",
            "Best model saved with accuracy: 78.13%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 4/10: 100%|██████████| 559/559 [01:19<00:00,  7.06it/s, acc=73.63%, loss=2.01]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4, Loss: 2.0079, Accuracy: 73.63%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 30/30 [00:02<00:00, 13.27it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 1.6996, Accuracy: 80.89%\n",
            "Best model saved with accuracy: 80.89%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 5/10: 100%|██████████| 559/559 [01:17<00:00,  7.20it/s, acc=76.67%, loss=1.87]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5, Loss: 1.8668, Accuracy: 76.67%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 30/30 [00:02<00:00, 13.14it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 1.6554, Accuracy: 81.10%\n",
            "Best model saved with accuracy: 81.10%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 6/10: 100%|██████████| 559/559 [01:19<00:00,  7.06it/s, acc=78.08%, loss=1.75]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 6, Loss: 1.7471, Accuracy: 78.08%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 30/30 [00:02<00:00, 13.22it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 1.4818, Accuracy: 83.23%\n",
            "Best model saved with accuracy: 83.23%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 7/10: 100%|██████████| 559/559 [01:17<00:00,  7.18it/s, acc=82.60%, loss=1.56]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 7, Loss: 1.5623, Accuracy: 82.60%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 30/30 [00:02<00:00, 13.21it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 1.4013, Accuracy: 85.77%\n",
            "Best model saved with accuracy: 85.77%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 8/10: 100%|██████████| 559/559 [01:16<00:00,  7.33it/s, acc=85.96%, loss=1.45]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 8, Loss: 1.4453, Accuracy: 85.96%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 30/30 [00:02<00:00, 13.23it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 1.3576, Accuracy: 86.41%\n",
            "Best model saved with accuracy: 86.41%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 9/10: 100%|██████████| 559/559 [01:16<00:00,  7.28it/s, acc=88.45%, loss=1.38]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 9, Loss: 1.3806, Accuracy: 88.45%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 30/30 [00:02<00:00, 13.38it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 1.3413, Accuracy: 87.47%\n",
            "Best model saved with accuracy: 87.47%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 10/10: 100%|██████████| 559/559 [01:16<00:00,  7.27it/s, acc=88.84%, loss=1.35]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 10, Loss: 1.3501, Accuracy: 88.84%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 30/30 [00:02<00:00, 13.34it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 1.3341, Accuracy: 87.69%\n",
            "Best model saved with accuracy: 87.69%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model1=create_vit_model(num_classes=200)\n",
        "model1.load_state_dict(torch.load('/content/working/models/vit_model.pth'))\n",
        "model1 = model1.cuda()  # Moves the model to GPU\n",
        "for param in model1.parameters():\n",
        "    param.data = param.data.to(torch.float32).cuda()\n",
        "\n",
        "model2=create_convnext_model(num_classes=200)\n",
        "model2.load_state_dict(torch.load('/content/working/models/convnext_model.pth'))\n",
        "model2 = model2.cuda()  # Moves the model to GPU\n",
        "for param in model2.parameters():\n",
        "    param.data = param.data.to(torch.float32).cuda()\n",
        "\n",
        "model3=create_efficientnet_model(num_classes=200)\n",
        "model3.load_state_dict(torch.load('/content/working/models/efficientnet_model.pth'))\n",
        "model3 = model3.cuda()  # Moves the model to GPU\n",
        "for param in model3.parameters():\n",
        "    param.data = param.data.to(torch.float32).cuda()"
      ],
      "metadata": {
        "id": "BwKpQ9yDEuih"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "models=[model1,model2]"
      ],
      "metadata": {
        "id": "VUDGtf5GSJir"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ensemble_model = ModelEnsemble(models)\n",
        "ensemble_model = ensemble_model.to(device)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-04-03T18:15:30.403048Z",
          "iopub.execute_input": "2025-04-03T18:15:30.403364Z",
          "iopub.status.idle": "2025-04-03T18:15:30.407503Z",
          "shell.execute_reply.started": "2025-04-03T18:15:30.403338Z",
          "shell.execute_reply": "2025-04-03T18:15:30.406543Z"
        },
        "id": "BZ16nOZYH_3O"
      },
      "outputs": [],
      "execution_count": 55
    },
    {
      "cell_type": "code",
      "source": [
        "# Test inference with ensemble model\n",
        "print(\"\\nPerforming inference on test set with ensemble model...\")\n",
        "test_images = sorted(os.listdir(test_path))\n",
        "\n",
        "\n",
        "predictions = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for img_name in tqdm(val_images):\n",
        "        img_path = img_name\n",
        "\n",
        "        # Process test image\n",
        "        cropped_image = detect_and_crop(img_path, is_train=False)\n",
        "        image_np = np.array(cropped_image)\n",
        "\n",
        "        # Apply transformations\n",
        "        image = val_transforms(image=image_np)['image']\n",
        "        image = image.unsqueeze(0).to(device)\n",
        "\n",
        "        # TTA (Test Time Augmentation)\n",
        "        outputs = tta_inference(ensemble_model, image, device, val_transforms)\n",
        "\n",
        "        # Get prediction\n",
        "        predicted_label = torch.argmax(outputs, dim=1).item()\n",
        "        predictions.append((img_name, predicted_label))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kj0jG6H032Oy",
        "outputId": "a965692d-ab35-43fb-d472-f46ce8c8950a"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Performing inference on test set with ensemble model...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 942/942 [03:26<00:00,  4.57it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "preds=[]\n",
        "for i in predictions:\n",
        "  preds.append(i[1])"
      ],
      "metadata": {
        "id": "aqdftDD2BG0O"
      },
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import precision_score\n",
        "\n",
        "\n",
        "# Compute precision score\n",
        "precision = precision_score(val_labels, np.array(preds), average='weighted')\n",
        "\n",
        "print(\"Precision Score:\", precision)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dgY_I2qQ4Jvw",
        "outputId": "c5ba9b92-7e42-4aaa-97dc-bb2c453ef5a4"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Precision Score: 0.9938782731776362\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "np.array(preds).shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P6qM_D-BCEO8",
        "outputId": "8e548a20-8382-49e1-c5d3-64bcf13d2808"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1883,)"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Test inference with ensemble model\n",
        "print(\"\\nPerforming inference on test set with ensemble model...\")\n",
        "test_images = sorted(os.listdir(test_path))\n",
        "\n",
        "\n",
        "predictions = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for img_name in tqdm(test_images, desc=\"Predicting\"):\n",
        "        img_path = os.path.join(test_path, img_name)\n",
        "\n",
        "        # Process test image\n",
        "        cropped_image = detect_and_crop(img_path, is_train=False)\n",
        "        image_np = np.array(cropped_image)\n",
        "\n",
        "        # Apply transformations\n",
        "        image = val_transforms(image=image_np)['image']\n",
        "        image = image.unsqueeze(0).to(device)\n",
        "\n",
        "        # TTA (Test Time Augmentation)\n",
        "        outputs = tta_inference(ensemble_model, image, device, val_transforms)\n",
        "\n",
        "        # Get prediction\n",
        "        predicted_label = torch.argmax(outputs, dim=1).item()\n",
        "        predictions.append((img_name, predicted_label))"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-04-03T18:15:31.963643Z",
          "iopub.execute_input": "2025-04-03T18:15:31.963932Z",
          "iopub.status.idle": "2025-04-03T18:15:32.142283Z",
          "shell.execute_reply.started": "2025-04-03T18:15:31.963910Z",
          "shell.execute_reply": "2025-04-03T18:15:32.141010Z"
        },
        "id": "5fzf-MP8H_3O",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d88b08ea-c052-4147-c5c1-966adf386b87"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Performing inference on test set with ensemble model...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Predicting: 100%|██████████| 2374/2374 [14:32<00:00,  2.72it/s]\n"
          ]
        }
      ],
      "execution_count": 52
    },
    {
      "cell_type": "code",
      "source": [
        "submission_df = pd.DataFrame(predictions, columns=[\"ID\", \"label\"])\n",
        "submission_df[\"label\"] = submission_df[\"label\"] + 1  # Adjusting for 1-indexed labels\n",
        "submission_df.to_csv(\"submission_ensemble_model.csv\", index=False)\n",
        "print(\"Submission file saved: submission.csv\")"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-04-03T18:15:36.099139Z",
          "iopub.execute_input": "2025-04-03T18:15:36.099422Z",
          "iopub.status.idle": "2025-04-03T18:15:36.119963Z",
          "shell.execute_reply.started": "2025-04-03T18:15:36.099399Z",
          "shell.execute_reply": "2025-04-03T18:15:36.119188Z"
        },
        "id": "7RzEdoTlH_3P",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "413d853c-c4bb-461f-84ab-d47b78605ac1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Submission file saved: submission.csv\n"
          ]
        }
      ],
      "execution_count": 53
    }
  ]
}